{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Using Recurrent Neural Networks\n",
    "\n",
    "Sentiment Analysis is a form of text classification where we take a text as input and assign a label to it. In this particular application, we want to take a *movie review* as input and analyze the *author's emotion* in that review. More specifically, we want to classify the review as being either **positive** or **negative**.\n",
    "\n",
    "We will be using *Neural Networks* to build our Sentiment Analysis system. To train our neural network, we will use the [Stanford’s Movies Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/), which contains *25000* training dataset and *25000* test dataset.\n",
    "\n",
    "This application is a type of Natural Language Processing. **Recurrent Neural Networks** are considered to handle such applications quite well. Note that NLP would be similar to image processing, if it was not for a few differences between text and images. Text inputs are often of variable length (unlike images which can be resized) and the important words can appear anywhere in a sentence. It is quite difficult to build a Neural Network to handle all types of sentences as input in a generic way. RNNs solve this issue by taking one word at a time and trying to remember the important information along the way. Its output at any time is then based on current input and whatever important information it has memorized along the way. **Long Short-Term Memory RNN** is a type of RNN where multiple LSTM cells are used, each capable of memorizing different type of information for some time. Details on LSTM RNN have already been discussed in class lectures.\n",
    "\n",
    "In the following code, we will use LSTM RNN to build a system capable of sentiment analysis on movie reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation\n",
    "\n",
    "Let's start by importing some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some python modules:\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "\n",
    "# PyTorch modules:\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use GPU for computations if CUDA is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0.dev20190805 cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.__version__, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset\n",
    "\n",
    "As mentioned above, we will be using the Stanford's Movies Review Dataset. The dataset is originally compressed to a `.tar.gz` file. We will check if the dataset has already been uncompressed, and if not, uncompress it before we can load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path that contains all our data:\n",
    "DATA_ROOT = 'dataset'\n",
    "# Path that should contain the uncompressed dataset.\n",
    "DATASET_PATH = os.path.join(DATA_ROOT, 'aclImdb')\n",
    "\n",
    "# Let's uncompress the dataset if the uncompressed folder is not present.\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print('Uncompressing dataset...')\n",
    "    fname = os.path.join(DATA_ROOT, 'aclImdb_v1.tar.gz')\n",
    "    with tarfile.open(fname, 'r') as f:\n",
    "        f.extractall(DATA_ROOT)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The organization of the dataset is as follows:\n",
    "\n",
    "- There are two folders: `train` for training and `test` for testing, each containing 25K data samples.\n",
    "- Inside each, there are two subfolders: `pos` for positive reviews and `neg` for negative reviews, each containing equal number of samples.\n",
    "\n",
    "Let's create a function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm to show a nice progress bar.\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load either the training or the test dataset.\n",
    "def read_imdb(folder='train'):\n",
    "    # Collect the data samples in a list.\n",
    "    data = []\n",
    "    \n",
    "    # Collect both the positive and the negative samples.\n",
    "    for label in ['pos', 'neg']:\n",
    "        # E.g.: positive training samples are in path: `aclImdb/train/pos`.\n",
    "        folder_name = os.path.join(DATASET_PATH, folder, label)\n",
    "        \n",
    "        # Open each file in this folder and read in the review text.\n",
    "        print('Reading samples from: ', folder_name, flush=True)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            \n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                # Each review is a unicode text. We will also remove new lines from the reviews.\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                \n",
    "                # Data samples are collected as tuples: (review, label)\n",
    "                # where label = 1 for positive and 0 for negative.\n",
    "                data.append((review, 1 if label == 'pos' else 0))\n",
    "                \n",
    "    # Before returning, shuffle all the positive and negative samples.\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read both the training and the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading samples from:  dataset/aclImdb/train/pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 44850.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading samples from:  dataset/aclImdb/train/neg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 44201.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading samples from:  dataset/aclImdb/test/pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 38439.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading samples from:  dataset/aclImdb/test/neg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 40234.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = read_imdb('train')\n",
    "test_data = read_imdb('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  I had recently been watching Johnny Test in an attempt to fi ... Label: 0\n",
      "Review:  The most embarrassing moment in this film is when Brady Corb ... Label: 0\n",
      "Review:  First let me preface this post by saying that I am a fan of  ... Label: 0\n",
      "Review:  The Second Renaissance, part 1 let's us show how the machine ... Label: 0\n",
      "Review:  This film is exactly what its title describes--an attempt to ... Label: 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data[:5]:\n",
    "    print('Review: ', x[0:60], '...', 'Label:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tokenization\n",
    "\n",
    "As with all machine learning systems, instead of raw data, we need features to feed into our system. The smallest useful unit in a text such as movie review is the word. So, we will tokenize the text data that we have into sequences of words. For our purpose, we will use a simple split by whitespace technique for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure everything is lowercase and split by whitespace.\n",
    "def tokenizer(text):\n",
    "    return [tok.lower() for tok in text.split()]\n",
    "\n",
    "\n",
    "# A function to tokenize all review samples in our dataset.\n",
    "def get_tokenized_imdb(data):\n",
    "    return [tokenizer(review) for review, _ in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Vocabulary\n",
    "\n",
    "A vocabulary is a set of all words present in our training dataset. Instead of just storing the presence of words in a set, we can further store the count of each word in the training set in a hashmap, which we can do with the help of Python's `Counter` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary: 46159\n"
     ]
    }
   ],
   "source": [
    "def get_vocab_imdb(data):\n",
    "    # First tokenize the review.\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    # Then collect each token in a Counter hashmap to build a vocabulary.\n",
    "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    \n",
    "    # PyTorch Vocab class will be used to represent our vocabulary.\n",
    "    return Vocab.Vocab(counter, min_freq=5)\n",
    "\n",
    "# Build vocabulary from the training set.\n",
    "vocab = get_vocab_imdb(train_data)\n",
    "\n",
    "print('Number of words in vocabulary:', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preprocessing\n",
    "\n",
    "Since we already have vocabulary of all words, for each data sample, we no longer need to store the reviews as sequence of words. Instead, we will store the sequence of word indices to the vocabulary.\n",
    "\n",
    "Because each review is of different length, it is not possible to combine several of them in a *mini-batch* tensor. So, we will fix the length of each to 500, by truncating longer reviews and adding *&lt;unk&gt;* tokens to shorter reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum review length:\n",
    "max_review_length = 500\n",
    "\n",
    "\n",
    "def truncate_or_pad(x):\n",
    "    # Note that index [0] is for <unk> token.\n",
    "    len_x = len(x)\n",
    "    return x[:max_review_length] if len_x > max_review_length else x + [0] * (max_review_length - len_x)\n",
    "\n",
    "\n",
    "def preprocess_imdb(data, vocab):\n",
    "    # First tokenize the data sample.\n",
    "    tokenized_data = get_tokenized_imdb(data)\n",
    "    \n",
    "    # Input feature vector is not the sequence of words but instead the sequence of word indices to the vocabulary.\n",
    "    features = torch.tensor([\n",
    "        truncate_or_pad([vocab.stoi[word] for word in words])\n",
    "        for words in tokenized_data\n",
    "    ])\n",
    "    \n",
    "    labels = torch.tensor([score for _, score in data])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Data Loader\n",
    "\n",
    "We will use PyTorch `DataLoader` class to create an iterable data loader, that is capable of loading random samples of data in batches.\n",
    "\n",
    "We will have three data loaders:\n",
    "\n",
    "- Training Data Loader: To load the 25K training samples.\n",
    "- Validation Data Loader: To load the half of the 25K test samples as validation set.\n",
    "- Test Data Loader: To load the other half of the 25K test samples as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Preprocess the training and the test datasets.\n",
    "train_set = Data.TensorDataset(*preprocess_imdb(train_data, vocab))\n",
    "# Divide test set into validation and test sets.\n",
    "half_test_size = int(len(test_data) / 2)\n",
    "validation_set = Data.TensorDataset(*preprocess_imdb(test_data[:half_test_size], vocab))\n",
    "test_set = Data.TensorDataset(*preprocess_imdb(test_data[half_test_size:], vocab))\n",
    "\n",
    "# Create the data loaders.\n",
    "train_iter = Data.DataLoader(train_set, BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "validation_iter = Data.DataLoader(validation_set, BATCH_SIZE, pin_memory=True)\n",
    "test_iter = Data.DataLoader(test_set, BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that the data loader works, let's iterate once with the training data loader and check the data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 500]) y: torch.Size([64])\n",
      "Number of batches: 391\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print('X:', X.shape, 'y:', y.shape)\n",
    "    break\n",
    "    \n",
    "print('Number of batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the Neural Network\n",
    "\n",
    "\n",
    "### 2.1 Architecture\n",
    "\n",
    "The architecture of our Neural Network is as follows:\n",
    "\n",
    "<img src=\"architecture.jpeg\" width=\"720px\">\n",
    "\n",
    "1. **Embedding**\n",
    "\n",
    "We will be using *GloVe* word embedding to convert the input words into feature vectors. Details about this approach is discussed in the accompanying slides. Below, we have just created a dummy embedding layer using PyTorch but we will see in the next section how we can initialize it with GloVe vocabulary. In our case, the size of the feature vectors will be 100.\n",
    "\n",
    "2. **LSTM Layers**\n",
    "\n",
    "We will use *Bidirectional LSTM* consisting of 2 layers and 100 hidden states.\n",
    "\n",
    "3. **Fully Connected Layer**\n",
    "\n",
    "We will then take the hidden states of both the initial and the final timesteps of the Bidirectional LSTM and connect it to a fully-connected linear network of neurons. The output of this layer will be two scalars, one representing the *negative* and the another representing the *positive* review.\n",
    "\n",
    "4. **Output and Error Function**\n",
    "\n",
    "The output layer consists of two neurons of the previous fully connected layer. The classification will be *positive* or *negative* based on whichever neuron has larger final value. To get the probability of the review to be in either of the class, we can use *softmax* function, if we want. To train the network, we will need some loss function. In our case, we will use *Cross Entropy based on Softmax Output* as the loss (error) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size=100, num_hiddens=100, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        \n",
    "        # Bidirectional LSTM layers\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Embed words into feature vectors:\n",
    "        embeddings = self.embedding(inputs.permute(1, 0))\n",
    "        \n",
    "        # Encode reviews using Bidirectional LSTM into hidden codes.\n",
    "        # Note that we will use the hidden states of both the first and the last timestep as the hidden codes.\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), -1)\n",
    "        \n",
    "        # Use the fully connected layer to classify the reivew based on the encoding.\n",
    "        return self.decoder(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the actual neural network using the above architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "num_hiddens = 100\n",
    "num_layers = 2\n",
    "\n",
    "net = BiRNN(vocab, embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 GloVe Word Embedding\n",
    "\n",
    "Since we will be using [GloVe](https://nlp.stanford.edu/pubs/glove.pdf) to embed our words into feature vectors, we need to initialize the embedding layer of our neural network using GloVe word vectors. To do so, we need the mapping of each word to their corresponding vectors. However, our training set is too small to generate the word vectors using GloVe. We will instead use a pre-trained GloVe vocabulary from Stanford's 6B dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=os.path.join(DATA_ROOT, \"glove\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map each word in our vocabulary to the index of the above pretrained GloVe vocabulary. For words that do not exist in the pretrained set, we will map them to *&lt;unk&gt;* (index = 0) token. Then, we will initialize the embedding layer of our neural network with these GloVe word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21203 out of vocabulary words.\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embedding(words, pretrained_vocab):\n",
    "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0])\n",
    "    \n",
    "    # Let's keep track of the number of out of vocabulary words.\n",
    "    oov_count = 0\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            idx = pretrained_vocab.stoi[word]\n",
    "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+= 1\n",
    "    \n",
    "    print('There are {} out of vocabulary words.'.format(oov_count))\n",
    "    return embed\n",
    "\n",
    "\n",
    "# Initialize the weights of the embedding layer so that it can map word into corresponding GloVe word vector.\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
    "# We won't be training the embedding layer.\n",
    "net.embedding.weight.required_gra = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Training\n",
    "\n",
    "Here are our training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate:\n",
    "lr = 0.01\n",
    "\n",
    "# Number of training epochs:\n",
    "epochs = 10\n",
    "\n",
    "# Optimization algorithm:\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "\n",
    "# Loss function:\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** of a classification is the percentage of correctly classified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "\n",
    "\n",
    "def eval_dataset(data_iter, net):\n",
    "    # accumulate accuracy for each sample and the number of samples.\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        y_hat = net(X.to(device))\n",
    "        acc_sum += calc_accuracy(y_hat, y.to(device))\n",
    "        n += y.shape[0]\n",
    "    \n",
    "    return acc_sum / n\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done using **back-propagation** of the error gradient. As mentioned previously, the error here is the Cross-Entropy error based on softmax output.\n",
    "\n",
    "During training, we also want to use our validation set to evaluate the network and make sure that the network does not overfit the training set. We do so by plotting both the training and the validation error and finding the point where we get the minimum validation error (or maximum validation accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.4378, training accuracy: 0.792, valid accuracy: 0.864, time: 74.2 sec\n",
      "Epoch: 2, loss: 0.0876, training accuracy: 0.941, valid accuracy: 0.845, time: 73.5 sec\n",
      "Epoch: 3, loss: 0.0227, training accuracy: 0.980, valid accuracy: 0.853, time: 72.6 sec\n",
      "Epoch: 4, loss: 0.0096, training accuracy: 0.989, valid accuracy: 0.846, time: 72.8 sec\n",
      "Epoch: 5, loss: 0.0048, training accuracy: 0.994, valid accuracy: 0.833, time: 72.3 sec\n",
      "Epoch: 6, loss: 0.0035, training accuracy: 0.994, valid accuracy: 0.818, time: 72.4 sec\n",
      "Epoch: 7, loss: 0.0039, training accuracy: 0.991, valid accuracy: 0.833, time: 73.2 sec\n",
      "Epoch: 8, loss: 0.0027, training accuracy: 0.994, valid accuracy: 0.829, time: 73.2 sec\n",
      "Epoch: 9, loss: 0.0014, training accuracy: 0.997, valid accuracy: 0.831, time: 74.2 sec\n",
      "Epoch: 10, loss: 0.0010, training accuracy: 0.997, valid accuracy: 0.830, time: 74.7 sec\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "# State of the network when we get the least validation error.\n",
    "best_state = {\n",
    "    'epoch': None,\n",
    "    'accuracy': None,\n",
    "    'model_state': None,\n",
    "    'optimizer_state': None,\n",
    "}\n",
    "\n",
    "# Function to record the network parameters.\n",
    "def record_best_state(epoch, new_accuracy):\n",
    "    best_accuracy = best_state['accuracy']\n",
    "    if best_accuracy is None or new_accuracy > best_accuracy:\n",
    "        best_state['epoch'] = epoch\n",
    "        best_state['accuracy'] = new_accuracy\n",
    "        best_state['model_state'] = net.state_dict()\n",
    "        best_state['optimizer_state'] = optimizer.state_dict()\n",
    "        \n",
    "        \n",
    "# Function to restore the network parameters.\n",
    "def restore_best_state():\n",
    "    net.load_state_dict(best_state['model_state'])\n",
    "    optimizer.load_state_dict(best_state['optimizer_state'])\n",
    "\n",
    "    \n",
    "# Record the training and validation accuracies for plotting.\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "batch_count = 0\n",
    "for epoch in range(epochs):\n",
    "    train_l_sum = 0.0\n",
    "    train_acc_sum = 0.0\n",
    "    n = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    for X, y in train_iter:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_l_sum += l.cpu().item()\n",
    "        train_acc_sum += calc_accuracy(y_hat, y)\n",
    "        \n",
    "        n += y.shape[0]\n",
    "        batch_count += 1\n",
    "    \n",
    "    valid_acc = eval_dataset(validation_iter, net)\n",
    "    train_acc = train_acc_sum / n\n",
    "    \n",
    "    # Let's keep track of the best validation accuracy:\n",
    "    record_best_state(epoch, valid_acc)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    valid_accs.append(valid_acc)\n",
    "    print(f'Epoch: {epoch + 1}, '\n",
    "          f'loss: {train_l_sum / batch_count:.4f}, '\n",
    "          f'training accuracy: {train_acc:.3f}, '\n",
    "          f'valid accuracy: {valid_acc:.3f}, '\n",
    "          f'time: {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the trend of training and validation accuracies as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xaxis = range(1, epochs+1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(xaxis, train_accs, label='Training Accuracy')\n",
    "plt.plot(xaxis, valid_accs, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy is clearly not the highest at the final epoch. So, we will restore the network parameters to the epoch where we had the highest validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 1\n",
      "Network restored.\n"
     ]
    }
   ],
   "source": [
    "print('Best epoch:', best_state['epoch'] + 1)\n",
    "restore_best_state()\n",
    "print('Network restored.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how well our network does in predicting sentiment of new movie reviews. We will create a function for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    tokens = tokenizer(sentence)\n",
    "    features = torch.tensor([vocab.stoi[word] for word in tokens], device=device)\n",
    "    label = torch.argmax(net(features.view((1, -1))), dim=1)\n",
    "    \n",
    "    return 'positive' if label.item() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment('This movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment('I do not really like this movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good.\n",
    "\n",
    "Let us calculate the final accuracy of the network using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network over test set: 82.42%\n"
     ]
    }
   ],
   "source": [
    "test_acc = eval_dataset(test_iter, net)\n",
    "print(f'Accuracy of the network over test set: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
